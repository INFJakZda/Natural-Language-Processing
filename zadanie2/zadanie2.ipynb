{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inżynieria lingwistyczna\n",
    "Ten notebook jest oceniany półautomatycznie. Nie twórz ani nie usuwaj komórek - struktura notebooka musi zostać zachowana. Odpowiedź wypełnij tam gdzie jest na to wskazane miejsce - odpowiedzi w innych miejscach nie będą sprawdzane (nie są widoczne dla sprawdzającego w systemie).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie domowe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 - eksploracja przestrzeni zagnieżdżeń\n",
    "Wczytajmy do przestrzeni plik zagnieżdżeń, który należy pobrać ze strony:\n",
    "https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.pl.vec Są to zagnieżdzenia dla języka polskiego uzyskane systemem fastText.\n",
    "\n",
    "Do przestrzeni wczytujemy tylko 100 tys. najczęstrzych słów, tak aby operacje przebiegały szybciej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff72904e199199567cefa7ecc512bc5b",
     "grade": false,
     "grade_id": "cell-a4ed145fec4874e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "def load_vectors(fname, limit = 100000):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    n = min(n,limit)\n",
    "    embeddings = np.empty((n,d), dtype = np.float)\n",
    "    words_idx = []\n",
    "    for i, line in enumerate(fin):\n",
    "        if i >= limit:\n",
    "            break\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        words_idx.append(tokens[0])\n",
    "        embeddings[i] =  np.array(tokens[1:]).astype(np.float)\n",
    "    return words_idx, embeddings\n",
    "words_idx, embeddings = load_vectors('wiki.pl.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższe zadania mają na celu poekserymentowanie z przestrzenią zagnieżdżeń, ale też zrozumienie stojącymi za nich operacji. Dozwolone jest korzystanie tylko z podstawowych operatorów Python i numpy (w szczególności zakaz dotyczy: sklearn, gensim, fasttext itd.)\n",
    "\n",
    "Jeśli potrzebujesz do dalszego przetwarzania przeprowadzenia jakichś normalizacji macierzy -- możesz wstępnie przetworzyć macierz zagnieżdzeń poniżej. Pamiętaj, że sprawdzarka będzie używała wywołań do `embeddings` (i `words_idx`) -- musisz nadpisać macierz zagnieżdzeń. To pole jest pomocnicze i nie podlega ocenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bad4efac5cfe3b895e04c7d1d616878c",
     "grade": false,
     "grade_id": "cell-6fee4cb7a7fea5c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# print(embeddings.shape)\n",
    "# print(embeddings[words_idx.index(\"dom\")].shape)\n",
    "embeddings = embeddings * (1 / np.linalg.norm(embeddings, axis=1))[:, np.newaxis]\n",
    "# print(embeddings.shape)\n",
    "# print(embeddings[words_idx.index(\"dom\")].shape)\n",
    "# print()\n",
    "# print(words_idx.index(\"ala\"))\n",
    "# print(words_idx.index(\"ma\"))\n",
    "# print(words_idx.index(\"kota\"))\n",
    "# print(embeddings[words_idx.index(\"dom\")].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcję, która obliczy podobieństwo kosinusowe pomiędzy dwoma wyrazami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89e46295053248c56d68caf5a00e3a81",
     "grade": false,
     "grade_id": "cell-433776f5de68cf95",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calc_sim(word_a, word_b, words_idx, embeddings):\n",
    "    emb_a = embeddings[words_idx.index(word_a)]\n",
    "    emb_b = embeddings[words_idx.index(word_b)]\n",
    "    cos_sim = np.dot(emb_a, emb_b)\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a0436c8372e1c2bc61b92bd05a6c765",
     "grade": true,
     "grade_id": "cell-890341bd1cbcc5d2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_almost_equal\n",
    "assert_almost_equal(calc_sim(\"bieber\", \"rihanna\", words_idx, embeddings), calc_sim(\"rihanna\", \"bieber\", words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policz podobieństwo pomiędzy wyrazem `bieber` a wyrazami:\n",
    "    - `rihanna`\n",
    "    - `piłsudski`\n",
    "    - `kanada`\n",
    "    - `polska`\n",
    "    - `piosenka`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_sim(\"bieber\", \"rihanna\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d0c5da4e71a95a4f3aacba9f9b4b664",
     "grade": false,
     "grade_id": "cell-3333712301dd0bbe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def print_similarity_to_bieber(word):\n",
    "    cos_sim = calc_sim(\"bieber\", word, words_idx, embeddings)\n",
    "    print(f\"bieber to {word}:\\t {str(cos_sim)}\")\n",
    "    \n",
    "print_similarity_to_bieber(\"rihanna\")\n",
    "print_similarity_to_bieber(\"piłsudski\")\n",
    "print_similarity_to_bieber(\"kanada\")\n",
    "print_similarity_to_bieber(\"polska\")\n",
    "print_similarity_to_bieber(\"piosenka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcję, która zwróci najbardziej podobne słowa (miara kosinusowa) do danego słowa `word`. W wyniku wypisz tylko `top` słów z najbliższymi zagnieżdżeniami, pomijając słowo `word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d174e9429ec96be4232e58eb4683ffb8",
     "grade": false,
     "grade_id": "cell-e8417832104ee5eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_similar(word, words_idx, embedding_matrix, top=10):\n",
    "    cosine_similarities = []\n",
    "    for word_idx in words_idx:\n",
    "        similarity = calc_sim(word, word_idx, words_idx, embedding_matrix)\n",
    "        cosine_similarities.append(similarity)\n",
    "    top_indicies = np.argsort(np.negative(cosine_similarities))[1:top+1]\n",
    "    \n",
    "    result_arr = []\n",
    "    for top_id in top_indicies:\n",
    "        result_arr.append(words_idx[int(top_id)])\n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff37028a810bf8da732cfdb41cc309b7",
     "grade": true,
     "grade_id": "cell-84f4627b3ebe0906",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(find_similar(\"radość\", words_idx, embeddings)) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znajdź najbardziej podobne słowa do kobieta, politechnika, mateusz, szczecin, niemcy, piłsudski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar(\"kobieta\", words_idx, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00f26fb5c5ebdbd5a5dd006c892c9aba",
     "grade": false,
     "grade_id": "cell-9e2eaa4a951e17b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "arr = [\"kobieta\", \"politechnika\", \"mateusz\", \"szczecin\", \"niemcy\", \"piłsudski\"]\n",
    "for word in arr:\n",
    "    print(word)\n",
    "    print(find_similar(word, words_idx, embeddings))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krótko skomentuj wyniki dla słowa `niemcy`. Które z powstałych analogii biorą się z semantycznego powiązania a które z semantycznego podobieństwa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c31c2929dc80543bebea431c05decbfd",
     "grade": true,
     "grade_id": "cell-f09fc185fd252182",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# powiazanie: niemieccy, niemieckie niemców - słowa te współwystepują jako\n",
    "# różne odmiany tego samego słowa ale niosąc to samo znaczenie.\n",
    "\n",
    "# podobieństwo: naziści, alianci, okupanci, polacy, itd - słowa te \n",
    "# występują na poodbnych pozycjach w zdaniu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcje szukającą brakującego elementu relacji ,,`word_a` jest do `word_a2` jak `word_b` jest do...''. Funkcja powinna zwrócić 10 najbardziej pasujących słow z pominięciem słów będących jej argumentami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e6e16dac4cb376f4d53a9d755cd46dc",
     "grade": false,
     "grade_id": "cell-63d29c3e720be966",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_pair(word_a, word_a2, word_b,  words_idx, matrix, top=10):\n",
    "    # YOUR CODE HERE\n",
    "    emb_a = matrix[words_idx.index(word_a)]\n",
    "    emb_a_2 = matrix[words_idx.index(word_a2)]\n",
    "    emb_b = matrix[words_idx.index(word_b)]\n",
    "    diff_a = emb_a - emb_a_2\n",
    "    emb_b_2 = emb_b - diff_a\n",
    "    \n",
    "    cosine_similarities = []\n",
    "    for word_idx in words_idx:\n",
    "        if word_idx != word_a and word_idx != word_a2 and word_idx != word_b:\n",
    "            similarity = np.dot(emb_b_2, embeddings[words_idx.index(word_idx)])\n",
    "        else:\n",
    "            similarity = 0\n",
    "        cosine_similarities.append(similarity)\n",
    "    top_indicies = np.argsort(np.negative(cosine_similarities))[:top]\n",
    "    \n",
    "    result_arr = []\n",
    "    for top_id in top_indicies:\n",
    "        result_arr.append(words_idx[int(top_id)])\n",
    "    return result_arr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7663a43e711a8e860bbc06d41b6ca904",
     "grade": true,
     "grade_id": "cell-0d5187c215c3d03c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert find_similar_pair( \"mężczyzna\", \"król\", \"kobieta\", words_idx, embeddings)[0] == \"królowa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pieniądze są do profesora jak wiedza do..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96e68dff29fccbb7ee7cb889aeaaf45c",
     "grade": false,
     "grade_id": "cell-8f5621bb8ded7490",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "find_similar_pair(\"pieniądze\", \"profesora\", \"wiedza\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mateusza jest do mateusz jak łukasza do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89ccdc6a4c7685a211811f0c6d5e796e",
     "grade": false,
     "grade_id": "cell-3215c64840cc460e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "find_similar_pair(\"mateusza\", \"mateusz\", \"łukasza\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warszawa jest do \"polska\" jak \"berlin\" do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2831d8f28423fd701364d67e72570994",
     "grade": false,
     "grade_id": "cell-8e4d868c692f267a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "find_similar_pair(\"warszawa\", \"polska\", \"berlin\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zurich jest do ETH jak Poznań do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_pair(\"zurich\", \"eth\", \"poznań\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niemcy są do Merkel jak Polska do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_pair( \"niemcy\", \"merkel\", \"polska\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na wektorach możemy wykonywać standardowe operacje algebry liniowej takie jak np. projekcja czyli rzutowanie danych na jakichś zbiór osi (więcej: notatki z algebry liniowej np. https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/least-squares-determinants-and-eigenvalues/projections-onto-subspaces/). W szczególności może to się przydać do zrzutowania słowa na przestrzeń w której pewny wybrany kierunek (wskazywany przez wektor) jest eliminowany.\n",
    "\n",
    "Do czego może to się przydać? Jeśli uruchomisz funkcję `find_similar` dla słowa ,,mateusza'' znajdziesz m.in. ,,łukasza'' ale także ,,ewangelia'', ,,ewangelisty'' i ,,apostoła''. Chcąc pominąc kontekst religijny tego słowa możesz zrzutować jego reprezentacje na przestrzeń bez wektora ,,ewangelia'' i poszukać jego najbliższych sąsiadów (którymi będą teraz po prostu imiona męskie). Zaimplementuj taką funkcję.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c635c05e6782ad6ef07a5ac3346f65c9",
     "grade": false,
     "grade_id": "cell-9c73750e7d423c6a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_with_rejection(word, remove, words_idx, matrix, top=10):\n",
    "    \"\"\"\n",
    "    Działanie analogiczne do find_similar z dodatkowym parametrem remove, \n",
    "    który jest *listą* słów, które należy wyrzucić poprzez projekcję.\n",
    "    Dla remove=[] powinno się zwracać dokładnie to samo co find_similar\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return find_similar(word, words_idx, matrix, top)\n",
    "print (\"Standardowe poszukiwanie:\", find_similar_with_rejection(\"mateusza\",[] , words_idx, embeddings))\n",
    "print (\"Poszukiwanie po projekcji:\", find_similar_with_rejection(\"mateusza\",[\"ewangelia\"] , words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cf5c44bd1df54c1da4106b8830dd322",
     "grade": true,
     "grade_id": "cell-b647aedbe8f9db7b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"ewangelii\" in find_similar_with_rejection(\"mateusza\",[] , words_idx, embeddings)\n",
    "assert \"ewangelii\" not in find_similar_with_rejection(\"mateusza\",[\"ewangelia\"] , words_idx, embeddings)\n",
    "assert \"ewangelisty\" not in find_similar_with_rejection(\"mateusza\",[\"ewangelia\"] , words_idx, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogicznie słowo ,,java'' jest nie tylko nazwą języka programownia (https://pl.wikipedia.org/wiki/Java_(ujednoznacznienie)) -- jest np. nazwą geograficzną (indonezyjska wyspa koło Sumatry). Sprawdź jakie wyrazy są podobne do \"java\" oraz po odrzuceniu kierunku \"javascript\" (tj. kierunku związanego z językami programowania)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e732ddade5feede63d07547766bcf949",
     "grade": false,
     "grade_id": "cell-d9d015bfeb8e25f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# nie zrobiłem :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbuj poekseprymentować samemu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a88f0a6d0571a66b40d04bc9cb8e65a",
     "grade": false,
     "grade_id": "cell-673e06a42de6bc26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# nie zrobiłem :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie projekcji w przestrzeni zagnieżdżeń może być jedną z prostych technik zwalczenia tzw. gender bias (http://wordbias.umiacs.umd.edu/) w reprezentacji słów. Okazuje się, że wykonanie projekcji macierzy zagnieżdżeń na przestrzeń w której ,,brakuje kierunku he-she'' może być bardzo prostą techniką zredukowania tego typu obciążenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 - zagnieżdżenia dokumentów\n",
    "W tym ćwiczeniu powócimy do zbioru tweetów, który analizowaliśmy w poprzednim dokumencie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import DataSet\n",
    "training_set = DataSet(['tweets.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in training_set.tweets:\n",
    "    print(i.text)\n",
    "    print(i.tokens)\n",
    "    print(i.clazz)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tym razem do zbudowania reprezentacji będziemy używać narzędzie Universal Sentence Encoder stworzone przez Googla na bazie głębokiej sieci uśredniającej (i architektur rekurencyjnych). Poniższy kod pokazuje sposób użycia tego narzędzia. \n",
    "Kod spokojnie można wywoływać na CPU -- choć ściąganie modelu trochę może potrwać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed([\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I am a sentence for which I would like to get its embedding\"])\n",
    "print (embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystując reprezetnację USE wytrenuj wybrany klasyfikator z pakietu `sklearn` i zweryfikuj jego jakość działania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ec9460c36ab328559c89319de53da65",
     "grade": false,
     "grade_id": "cell-26c33314c55313ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "tweet_text = [tweet.text for tweet in training_set.tweets]\n",
    "tweet_emb = embed(tweet_text).numpy()\n",
    "\n",
    "tweet_clazzes = [tweet.clazz for tweet in training_set.tweets]\n",
    "\n",
    "def fit_classifier_use(tokens, clazzes, no_features):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        tokens, clazzes, test_size=0.1, random_state=42)\n",
    "    \n",
    "    text_clf = SGDClassifier(loss='hinge', penalty='l2',\n",
    "                        alpha=1e-3, random_state=42,\n",
    "                        max_iter=5, tol=None)\n",
    "    text_clf.fit(X_train, y_train)\n",
    "    \n",
    "    predicted = text_clf.predict(X_test)\n",
    "    \n",
    "    # return: accuracy\n",
    "    return np.mean(predicted == y_test)\n",
    "\n",
    "fit_classifier_use(tweet_emb, tweet_clazzes, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skomentuj wyniki i odnieś je do wyników z poprzedniego zadania domowego. Na ile użycie reprezentacji rozproszonych pozwoliło na poprawę wyników?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "635819ecfcec9e909b5f4b2261ea14a5",
     "grade": true,
     "grade_id": "cell-e08f7b8feff88383",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# W 3 przypadkach użyto tego samego klasyfikatora, jedyną różnicą \n",
    "# (jak się okazało bardzo znaczącą) byłą reprezentacja wejścia.\n",
    "\n",
    "# 1) wykorzystujący hashowanie cech\n",
    "#    acc: 0.43 ~ 0.6 (w zależności od parametru wymiaru macierzy danych)\n",
    "\n",
    "# 2) wykorzytujący Bag-of-clusters\n",
    "#    acc: 0.57\n",
    "\n",
    "# 3) wykorzytujący USE embeddings\n",
    "#    acc: 0.64\n",
    "\n",
    "# Wnioski: USE mocno poprawiły wynik, jednak w tym przypadku aby osiągnąć\n",
    "#          jeszcze lepsze wyniki należało by użyć bardziej zaawansowanego \n",
    "#          klasyfikatora lub innych technik. Jednakże widać dużą przewgę \n",
    "#          USE nad pozostałymi reprezentacjami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3 - konstruowanie zagnieżdżeń\n",
    "W tym ćwiczeniu kontynuujemy pracę z tweetami, ale pomijamy całkowicie ich klasy. Zbiór tweetów potraktujemy jako korpus do nauczenia zagnieżdżeń słów przy pomocy macierzy PMI.\n",
    "- Wypełnij macierz kontekst - dokument przy użyciu symetrycznego okna o promieniu 4 (po 4 słowa w każdą stronę)\n",
    "- Możesz ograniczyć słownictwo do 10K słów\n",
    "- Przekształć macierz w macierz PPMI\n",
    "- Stwórz zagnieżdżenia wykorzystując dekompozycję SVD do wybranej wymiarowości $d$ (ze względu na koszt obliczeniowy może to być mała wymiarowość np. $d=10$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d780996410f05351b8dc57e50531c78d",
     "grade": true,
     "grade_id": "cell-dc2433e668962e28",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "RADIUS = 4\n",
    "\n",
    "tweet_texts = [tweet.text for tweet in training_set.tweets]\n",
    "test_texts = [\n",
    "    \"I like Information Retrieval and I like Statistics.\",\n",
    "    \"I enjoy flying.\"\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "def create_hal_matrix(texts):\n",
    "    \n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    size = len(tokenizer.word_index)\n",
    "    # print(tokenizer.texts_to_sequences([\"sth the a an\"]))\n",
    "\n",
    "    hal_matrix = np.zeros((size, size))\n",
    "\n",
    "    sentences_sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    for sentences_sequence in sentences_sequences:\n",
    "#         print(sentences_sequence)\n",
    "        for i, sequence in enumerate(sentences_sequence):\n",
    "#             print(sequence, i)\n",
    "            for n in range(1, RADIUS + 1):\n",
    "                index_prev = i - n\n",
    "                index_post = i + n\n",
    "                value = RADIUS + 1 - n\n",
    "                if index_prev >= 0:\n",
    "                    hal_matrix[sequence - 1, sentences_sequence[index_prev] - 1] += value\n",
    "#                     print(\"PREV\", sentences_sequence[index_prev], RADIUS + 1 - n)\n",
    "                if index_post < len(sentences_sequence):\n",
    "                    hal_matrix[sequence - 1, sentences_sequence[index_post] - 1] += value\n",
    "#                     print(\"POST\", sentences_sequence[index_post], RADIUS + 1 - n)\n",
    "#     print(hal_matrix)\n",
    "    return hal_matrix\n",
    "\n",
    "def matrix_to_ppmi(matrix):\n",
    "    ppmi_matrix = np.zeros_like(matrix, dtype='float64')\n",
    "    matrix_sum = np.sum(matrix)\n",
    "    matrix_row_sum = np.sum(matrix, axis = 1)\n",
    "    matrix_col_sum = np.sum(matrix, axis = 0)\n",
    "    \n",
    "\n",
    "    for index, x in np.ndenumerate(matrix):\n",
    "        ppmi_matrix[index] = (matrix[index] * matrix_sum) / (matrix_row_sum[index[0]] * matrix_col_sum[index[1]])\n",
    "    \n",
    "    ppmi_matrix = np.log2(ppmi_matrix)\n",
    "    ppmi_matrix = np.maximum(ppmi_matrix, 0)\n",
    "#     print(ppmi_matrix)\n",
    "    \n",
    "    return ppmi_matrix\n",
    "\n",
    "hal_matrix = create_hal_matrix(tweet_texts)\n",
    "# hal_matrix = np.array([\n",
    "#     [0, 0, 1, 0, 1],\n",
    "#     [0, 0, 1, 0, 1],\n",
    "#     [2, 1, 0, 1, 0],\n",
    "#     [1, 6, 0, 4, 0],\n",
    "#     [0, 0, 0, 0, 0]\n",
    "# ])\n",
    "hal_matrix = hal_matrix.astype('float64')\n",
    "# print(hal_matrix)\n",
    "\n",
    "ppmi_matrix = matrix_to_ppmi(hal_matrix)\n",
    "# print(ppmi_matrix)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=10, n_iter=8, random_state=42)\n",
    "svd.fit(ppmi_matrix)\n",
    "\n",
    "my_embeddings = svd.transform(ppmi_matrix)\n",
    "\n",
    "# print(hal_matrix)\n",
    "# print(ppmi_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestuj działanie Twoich zagnieżdżeń wykorzystując funkcję `find_similar` na wybranych słowach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccb11abbddd43b64c364aea20584f1dd",
     "grade": true,
     "grade_id": "cell-f6fa13a67093698a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "my_embeddings = my_embeddings * (1 / np.linalg.norm(my_embeddings, axis=1))[:, np.newaxis]\n",
    "arr = [\"good\", \"ok\", \"trump\", \"dog\"]\n",
    "for word in arr:\n",
    "    print(word)\n",
    "    print(find_similar(word, list(tokenizer.word_index.keys()), my_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
